---
title: 'Assignment 3: Logistic Regression'
author: "Henri V"
date: "2023-11-12"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, results = F)
```

# Assignment 3: Logistic Regression


## Install required packages

* Note that running this procedure requires:
  * Tidyverse
  * gt
  * here

```{r,include=F}

if (!require(here) == T) {
  install.packages("here") #Checks if the package is NOT installed. If this evaluates to TRUE, runs installation.  
}
library(here)


if (!require(tidyverse) == T) {
  install.packages("tidyverse")
}
library(tidyverse)

if (!require(gt) == T) {
  install.packages("gt")   
}
library(gt)
```

## Reading source data into R

* First off, we read the required source data into R. 
  * A separate script was created for this.
  * Data frame "alc" contains the necessary data
  
```{r,  echo=T}
source(here("Scripts/create_data_assignment3.R"))
```

## Forming initial hypotheses

* In this excercise, we try to find out if there is a connection between alcohol consumption and other variables
* The meanings of each variable are explained under "Additional variable information" [here](https://archive.ics.uci.edu/dataset/320/student+performance) 
* The following 4 are chosen and initial hypotheses for the proposed relationship formed:
  * _absences_: could high rates of alcohol consumption be affiliated with high rates of absences from school?   
  * _health_: hypothesis is that people consuming higher doses of alcohol may have a worse health condition than those who abstain?   
  * _failures_: increased likelihood of course failures among heavy drinkers? 
  * _famrel_: increased likelihood of heavy drinking leading to family conflicts (poorer family relations?) 
  
  
## Summary table for variables, graphical examinatons  

```{r, echo}  
taulukko<-alc %>% group_by(high_use) %>% summarise(`Average absence` = mean(absences),
                                            `St.Dev, absences.`=sd(absences),
                                            `Average health` = mean(health),
                                            `St.Dev., health`=sd(health),
                                            `Average failure` = mean(failures),
                                            `St.Dev., failures`=sd(failures),
                                            `Average family relations` = mean(famrel),
                                            `St.Dev., family relations` = sd(famrel))
```

```{r, results=T}
gt(taulukko) %>%
  fmt_number(decimals=2) %>% cols_align("center") %>% opt_stylize(style=1, color="green")  %>% tab_header("Summary table")

```

### Absence

* on average, absence rates seem to be higher in the high alcohol consumption group than in the low consumption group (6.4 versus 3.7). More variation in the high-consuming group.  
  * Consistent with initial assumptions.

```{r}

ggplot(alc, aes(x = high_use, y = absences)) + geom_boxplot() + ggtitle("Distribution of `absences` values by group")
```

### Health

* Regarding health, differences between groups seem small.
  * Contrary to expectation, alc consumption does not seem to differ between groups?
* Mean 3.5 versus 3.7, almost the same. SD at 1.4 in both...




```{r}
ggplot(alc, aes(x = high_use, y = health)) + geom_boxplot()+ggtitle("Distribution of `health` values by group")
```

### Failure rate
* Failure rate is on average slightly higher in the high consumption group, as was assumed, but the difference is less pronounced than I was expecting.
* 0 failures seem to be the most common situation regardless of group, any other values are marginally represented in comparison. 


```{r, results=T, echo=F, message=F}
Frek<-(alc %>% group_by(high_use, failures) %>% summarise(n = n())) 

gt(Frek) %>%  
  cols_align("center") %>% 
  opt_stylize(style=1, color="green") %>% 
  tab_header("Frequency of `failure` values by group")

```



### Family relations


```{r, echo =F}

ggplot(alc, aes(x = high_use, y = famrel)) + geom_boxplot()

```

* Family relation values appear to be on average slightly poorer in the high alcohol consumption group.
* This is the sort of finding I expected to see, but the magnitude of difference between the groups is lower than I thought it would be. . 


## Logistic regression

### Defining the GLM model, and extracting the coefficients from summary

```{r}

# find the model with glm()
m <- glm(high_use ~ failures+absences+health+famrel, data = alc, family = "binomial")

# create model summary and extract the coeffs
summary(m)

coeffs<-m %>% summary() %>% coefficients()
```
* All others except family relations are positively correlated with high alcohol use. 
* Strongest positive correlation  is Failures. Also statistically significant.
* Also absences correlates positively, shows statistical significance.
* Family relations correlates negatively, is statistically significant. Pretty much as I would expect
* Health: no statistical significance seen in this data. Does not necessarily indicate that there is absolutely no link between health status and drinking in existence even if this data doesn't show it, as the body of medical evidence in published literature indicates otherwise. Would a different set of data/different measured metric have given a different outcome? Could the students self-assess their health status as more rosy than it really is, as not all aspects of ill health are immediately obvious to the respondent (e.g. high blood pressure)?   
* Next step: odds ratios 
  
### Converting coeffs to odds ratios, calculating confidence intervals
  
  
```{r, results=T, echo=T, message=F}

OddsRatio<-exp(coeffs)
ConfInt<- confint(m)

Result<-cbind(OddsRatio, ConfInt)

```




```{r, results=T, echo=T}
print(Result)

```
* These estimates are on a different scale than in the more familiar linear regression
  * There, a coefficient can be interpreted directly. When the value of the independent variable increases by 1 unit, the dependent's value changes by 1 unit as a response . Not the case here.   
  * These are _odds based_ and need to be thought of in terms of likelihood, not as a direct change in the value of dependent variable's value as independent's value changes.
  
* Odds ratios quantify the strength of the relationship between dependent and independent vars. 
* If OR = 1, the odds of being a heavy drinker or not are the same, regardless of the dependent variable.
* Here, failures has the strongest link with heavy drinking. An increase of failures by 1 increases the likelihood of being a heavy drinker by almost 2-fold (1.8)
* For absences and health, the increases in odds are less pronounced. 
* The relationship with famrel is inverted in comparison to the others: Famrel increase decreases the odd of heavy drinking by 0.25. This was pretty much the expected outcome


### Predictive power

## Refining the model: culling variables that showed no statistical significance
* Health will be dropped, all others remain

```{r, results=T, echo=T}
m <- glm(high_use ~ failures+absences+famrel, data = alc, family = "binomial")

```

## Predicting the probability of having the status "high use" based on the model, add as new column to alc frame

* here, we take the model from before, and based on it calculate the probability that a certain student (row in data) has the attribute "Strong drinker".    

* Then, we use the probabilities to make a prediction of high_use. 
* The model takes actual values from the data, and based on them estimates how likely it is that a certain row (student) has the attribute (heavy drinker) These prediction may, or may not, match what the actual value was on each row. 

```{r, results=T, echo=T}
 
alc$predicted_probabilities <- predict(m, type = "response")  #type determines which outcome is given, see ?predict


alc <- mutate(alc,prediction  = predicted_probabilities > 0.5) #Selects those, for which the model indicates should have more than 50% prob of being a heavy drinker. T if over 50, F if not. 


```

## Comparison of actual values (High use or not) and predicted values. How many mismatches in actual terms, how accurate were we?


```{r, results=T, echo=F}


x<-alc %>% select(failures, absences, famrel, high_use, predicted_probabilities, prediction) 
x<-table(high_use = x$high_use, prediction = x$prediction)

y<-x
y<-(y/370)*100

```

### Direct comparison by counts and percentages
```{r, results=T}
print(x)
print (y)
```

* Rows that were in reality (as in the value of high_use) FALSE, were predicted to be FALSE by the model (correctly classified) 242  times (65.4 %)   
* For TRUE-TRUE case, just 19 observations were recorded (5 %). In this kind of tabulation, it has to be remembered that the groups are not nearly equal in size. There's just 111 TRUE cases, and 259 FALSEs. 

### Penalty function definition

```{r, echo=T}

# define a loss function (mean prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5 
  mean(n_wrong)
}

```

#### Idea of the function, what it does and why
* Task: Find the proportion of "light drinkers" that the model misclassified as "heavies"
* Set probability of being heavy drinker at 0%
* Function takes: 
  * class" of a student, can be either 1 or 0, heavy drinker or not. 
  * Then it takes a set probability, and substracts them. 
* Say, that it finds a student with a class of 0. 
* Substracts the probability (0) and class value. If class is 0 and prob is 0, result is also 0, lower than 0.5 (FALSE).This is a correct classification, as we just set the probability of being a heavy drinker at 0.
* If it were a positive number, it'd have found a heavy drinker (1- 0 = 1, which is > 0.5, TRUE), despite the  prob being 0 (=found a misclassed case)

* A converse case: we want to find cases in which class is 0, even though we set the probability of being heavy drinker at 100 %
* Conversely, if it was set at 1 (100% likelihood of being a heavy drinker), and the function finds a class of 1, the function would look like: abs(1-1) = 0, which is not > 0.5. We would have a correctly classed case.  
* If it finds a misclassified one, it'd be  (0-1) = -1, which as an absolute number (drop the minus) is higher than 0.5. 

* In each scenario, the function also calculates the mean

* Here, we set the function to find students of class 0, and check if they are mismatched as 1


```{r, results=T}

loss_func(class = alc$high_use, prob = 0)

```



* The average number of mismatches,  of students that were found to be of class 1, despite the probability of of being such set at zero, was 0.3.
* If there were only mismatches found by the function  (i.e. all 1:s in the n_wrong object), the mean would be 1. The less mismatches, the lower the value --> Better result regarding accuracy. 
```{r, results=T}

loss_func(class = alc$high_use, prob = 1)

```
* The opposite case (0's found when probability was 1) was 0.7. 

* Model appears to misclassify 0:s as 1:s almost doubly more often, than the opposite way.  


### Cross validation

```{r, results=T}


# K-fold cross-validation
library(boot)
cv <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = 10)

# average number of wrong predictions in the cross validation
cv$delta[1]

```

* Compared to the model in the excercise, these predictors we now look at have a bit higher mean prediction error, but not overwhelmingly so. The difference is rather small (circa 0.3 versus 0.26)

_further delving into the bonus section if time allows..._

